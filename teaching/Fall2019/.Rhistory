for (i in 1:M) {
mu1 <- mu[i]
pvalues <- replicate(m, expr = {
#simulate under alternative mu1
x <- rnorm(n, mean = mu1, sd = sigma)
ttest <- t.test(x,
alternative = "two.sided", mu = mu0)
# try "two.sided" and "less"
ttest$p.value  } )
power[i] <- mean(pvalues <= .05)
}
#par(ask = TRUE)
library(Hmisc)  #for errbar
plot(mu, power)
abline(v = mu0, lty = 1)
abline(h = .05, lty = 1)
install.packages("bootstrap")
### Example 7.1
set.seed(8)
x=rpois(10,2)
x
table(x)
summary(x)
?table
ecdf(x)
x
plot(ecdf(x))
plot(dpois(1:5,2))
plot(ecdf(rpois(1000,2)))
par(mfrow=c(1,2))
plot(ecdf(x))
plot(ecdf(rpois(1000,2)))
par(mfrow=c(1,2))
plot(ecdf(x))
plot(ecdf(rpois(1000,2)), main='Poi(2)')
plot(ecdf(rpois(1000,2)), main='Poi(2)', ylab="F(x)")
### Example 7.1
set.seed(8)
x=rpois(10,2)
x
hist(x)
table(x)
library(bootstrap)    #for the law data
data("law")
law
cor(law$LSAT, law$GPA)
law82
cor(law$LSAT, law$GPA)
cor(law82$LSAT, law82$GPA)
#set up the bootstrap
B <- 200            #number of replicates
n <- nrow(law)      #sample size
R <- numeric(B)     #storage for replicates
#bootstrap estimate of standard error of R
for (b in 1:B) {
#randomly select the indices
i <- sample(1:n, size = n, replace = TRUE)
LSAT <- law$LSAT[i]       #i is a vector of indices
GPA <- law$GPA[i]
R[b] <- cor(LSAT, GPA)
}
#output
se.R <- sd(R)
se.R
hist(R, prob = TRUE)
dev.off()
hist(R, prob = TRUE)
abline(v=cor(law$LSAT, law$GPA))
r <- function(x, i) {
#want correlation of columns 1 and 2
cor(x[i,1], x[i,2])
}
library(boot)       #for boot function
?boot    # check statistic
obj <- boot(data = law, statistic = r, R = 2000)
obj
y <- obj$t
y
sd(y)
#sample estimate for n=15
theta.hat <- cor(law$LSAT, law$GPA)
#bootstrap estimate of bias
B <- 2000   #larger for estimating bias
n <- nrow(law)
theta.b <- numeric(B)
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
LSAT <- law$LSAT[i]
GPA <- law$GPA[i]
theta.b[b] <- cor(LSAT, GPA)
}
bias <- mean(theta.b - theta.hat)
bias
# compare
obj
B <- 2000   #larger for estimating bias
n <- nrow(law)
theta.b <- numeric(B)
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
LSAT <- law$LSAT[i]
GPA <- law$GPA[i]
theta.b[b] <- cor(LSAT, GPA)
}
bias <- mean(theta.b - theta.hat)
bias
data(patch, package = "bootstrap")
patch
patch
n <- nrow(patch)  #in bootstrap package
B <- 2000
theta.b <- numeric(B)
theta.hat <- mean(patch$y) / mean(patch$z)
#bootstrap
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
y <- patch$y[i]
z <- patch$z[i]
theta.b[b] <- mean(y) / mean(z)
}
bias <- mean(theta.b) - theta.hat
se <- sd(theta.b)
print(list(est=theta.hat, bias = bias,
se = se, cv = bias/se))
print(list(est=theta.hat, bias = bias,
se = se))
data(patch, package = "bootstrap")
patch
n <- nrow(patch)  #in bootstrap package
B <- 2000
theta.b <- numeric(B)
theta.hat <- mean(patch$y) / mean(patch$z)
#bootstrap
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
y <- patch$y[i]
z <- patch$z[i]
theta.b[b] <- mean(y) / mean(z)
}
bias <- mean(theta.b) - theta.hat
se <- sd(theta.b)
print(list(est=theta.hat, bias = bias,
se = se))
alpha <- .1
n <- 30
m <- 2500
epsilon <- c(seq(0, .15, .01), seq(.15, 1, .05))
N <- length(epsilon)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) {           #for each epsilon
e <- epsilon[j]
sktests <- numeric(m)
for (i in 1:m) {       #for each replicate
sigma <- sample(c(1, 10), replace = TRUE,
size = n, prob = c(1-e, e))
x <- rnorm(n, 0, sigma)
sktests[i] <- as.integer(abs(sk(x)) >= cv)
}
pwr[j] <- mean(sktests)
}
### Example 6.4 (Confidence interval for variance)
n <- 20
alpha <- .05
x <- rnorm(n, mean=0, sd=2)
UCL <- (n-1) * var(x) / qchisq(alpha, df=n-1)
UCL
### Example 6.5 (MC estimate of confidence level)
#set.seed(123)
n <- 20
alpha <- .05
UCL <- replicate(1000, expr = {
x <- rnorm(n, mean = 0, sd = 2)
(n-1) * var(x) / qchisq(alpha, df = n-1)
} )
#count the number of intervals that contain sigma^2=4
sum(UCL > 4)
#or compute the mean to get the confidence level
a = mean(UCL > 4)
a
# standard error
sqrt(a*(1-a)/1000)
### Example 6.6 (Empirical confidence level)
# non-Gaussian case, chisquare(2)
n <- 20
alpha <- .05
UCL <- replicate(1000, expr = {
x <- rchisq(n, df = 2)
(n-1) * var(x) / qchisq(alpha, df = n-1)
} )
sum(UCL > 4)
a = mean(UCL > 4)
a
# standard error
sqrt(a*(1-a)/1000)
### Example 6.7 (Empirical Type I error rate)
# t-test for mean with unknown sigma
n <- 20
alpha <- .05
mu0 <- 500
sigma <- 100
m <- 10000          #number of replicates
p <- numeric(m)     #storage for p-values
for (j in 1:m) {
x <- rnorm(n, mu0, sigma)
ttest <- t.test(x, alternative = "greater", mu = mu0)
p[j] <- ttest$p.value
}
p.hat <- mean(p < alpha)
se.hat <- sqrt(p.hat * (1 - p.hat) / m)
print(c(p.hat, se.hat))
### Example 6.8 (Skewness test of normality)
n <- c(10, 20, 30, 50, 100, 500) #sample sizes
cv <- qnorm(.975, 0, sqrt(6/n))  #crit. values for each n
sk <- function(x) {
#computes the sample skewness coeff.
xbar <- mean(x)
m3 <- mean((x - xbar)^3)
m2 <- mean((x - xbar)^2)
return( m3 / m2^1.5 )
}
#n is a vector of sample sizes
#we are doing length(n) different simulations
p.reject <- numeric(length(n)) #to store sim. results
m <- 10000                     #num. repl. each sim.
for (i in 1:length(n)) {
sktests <- numeric(m)       #test decisions
for (j in 1:m) {
x <- rnorm(n[i])
#test decision is 1 (reject) or 0
sktests[j] <- as.integer(abs(sk(x)) >= cv[i] )
}
p.reject[i] <- mean(sktests) #proportion rejected
}
p.asym = p.reject
plot(p.asym, ylim=c(0,.1), type='o', lwd=2)
abline(h=0.05, lty=2, lwd=2, col='red')
# Use an exact variance to calculate the critical values
cv <- qnorm(.975, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
#n is a vector of sample sizes
#we are doing length(n) different simulations
p.reject <- numeric(length(n)) #to store sim. results
m <- 10000                     #num. repl. each sim.
for (i in 1:length(n)) {
sktests <- numeric(m)       #test decisions
for (j in 1:m) {
x <- rnorm(n[i])
#test decision is 1 (reject) or 0
sktests[j] <- as.integer(abs(sk(x)) >= cv[i] )
}
p.reject[i] <- mean(sktests) #proportion rejected
}
p.reject
lines(p.reject, lwd=2, type='b', col='blue')
### Example 6.9 (Empirical power)
n <- 20
m <- 1000
mu0 <- 500
sigma <- 100
mu <- c(seq(450, 650, 10))  #alternatives
M <- length(mu)
power <- numeric(M)
for (i in 1:M) {
mu1 <- mu[i]
pvalues <- replicate(m, expr = {
#simulate under alternative mu1
x <- rnorm(n, mean = mu1, sd = sigma)
ttest <- t.test(x,
alternative = "greater", mu = mu0)
# try "two.sided" and "less"
ttest$p.value  } )
power[i] <- mean(pvalues <= .05)
}
#par(ask = TRUE)
library(Hmisc)  #for errbar
plot(mu, power)
abline(v = mu0, lty = 1)
abline(h = .05, lty = 1)
#add standard errors
se <- sqrt(power * (1-power) / m)
errbar(mu, power, yplus = power+se, yminus = power-se,
xlab = bquote(theta))
abline(v = mu0, lty = 1)
abline(h = .05, lty = 1)
lines(mu, power, lty=3)
detach(package:Hmisc)
#par(ask = FALSE)
alpha <- .1
n <- 30
m <- 2500
epsilon <- c(seq(0, .15, .01), seq(.15, 1, .05))
N <- length(epsilon)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) {           #for each epsilon
e <- epsilon[j]
sktests <- numeric(m)
for (i in 1:m) {       #for each replicate
sigma <- sample(c(1, 10), replace = TRUE,
size = n, prob = c(1-e, e))
x <- rnorm(n, 0, sigma)
sktests[i] <- as.integer(abs(sk(x)) >= cv)
}
pwr[j] <- mean(sktests)
}
#plot power vs epsilon
plot(epsilon, pwr, type = "b",
xlab = bquote(epsilon), ylim = c(0,1))
abline(h = .1, lty = 3)
se <- sqrt(pwr * (1-pwr) / m)  #add standard errors
lines(epsilon, pwr+se, lty = 3, lwd=2, col=2)
lines(epsilon, pwr-se, lty = 3, lwd=2, col=2)
# initialize input and output
library(energy)
alpha <- .1
n <- 30
m <- 100        #try small m for a trial run
test1 <- test2 <- test3 <- numeric(m)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
sim <- matrix(0, 11, 4)
# estimate power
for (i in 0:10) {
epsilon <- i * .1
for (j in 1:m) {
e <- epsilon
sigma <- sample(c(1, 10), replace = TRUE,
size = n, prob = c(1-e, e))
x <- rnorm(n, 0, sigma)
test1[j] <- as.integer(abs(sk(x)) >= cv)
test2[j] <- as.integer(
shapiro.test(x)$p.value <= alpha)
test3[j] <- as.integer(
mvnorm.etest(x, R=200)$p.value <= alpha)
}
print(c(epsilon, mean(test1), mean(test2), mean(test3)))
sim[i+1, ] <- c(epsilon, mean(test1), mean(test2), mean(test3))
}
detach(package:energy)
# plot the empirical estimates of power
plot(sim[,1], sim[,2], ylim = c(0, 1), type = "l",
xlab = bquote(epsilon), ylab = "power")
lines(sim[,1], sim[,3], lty = 2, col=2)
lines(sim[,1], sim[,4], lty = 4, col=3)
abline(h = alpha, lty = 3)
legend("topright", 1, c("skewness", "S-W", "energy"),
lty = c(1,2,4), col=1:3, inset = .02)
alpha <- .1
n <- 30
m <- 2500
epsilon <- c(seq(0, .15, .01), seq(.15, 1, .05))
N <- length(epsilon)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) {           #for each epsilon
e <- epsilon[j]
sktests <- numeric(m)
for (i in 1:m) {       #for each replicate
sigma <- sample(c(1, 10), replace = TRUE,
size = n, prob = c(1-e, e))
x <- rnorm(n, 0, sigma)
sktests[i] <- as.integer(abs(sk(x)) >= cv)
}
pwr[j] <- mean(sktests)
}
#plot power vs epsilon
plot(epsilon, pwr, type = "b",
xlab = bquote(epsilon), ylim = c(0,1))
abline(h = .1, lty = 3)
se <- sqrt(pwr * (1-pwr) / m)  #add standard errors
lines(epsilon, pwr+se, lty = 3, lwd=2, col=2)
lines(epsilon, pwr-se, lty = 3, lwd=2, col=2)
# initialize input and output
library(energy)
alpha <- .1
n <- 30
m <- 100        #try small m for a trial run
test1 <- test2 <- test3 <- numeric(m)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
sim <- matrix(0, 11, 4)
# estimate power
for (i in 0:10) {
epsilon <- i * .1
for (j in 1:m) {
e <- epsilon
sigma <- sample(c(1, 10), replace = TRUE,
size = n, prob = c(1-e, e))
x <- rnorm(n, 0, sigma)
test1[j] <- as.integer(abs(sk(x)) >= cv)
test2[j] <- as.integer(
shapiro.test(x)$p.value <= alpha)
test3[j] <- as.integer(
mvnorm.etest(x, R=200)$p.value <= alpha)
}
print(c(epsilon, mean(test1), mean(test2), mean(test3)))
sim[i+1, ] <- c(epsilon, mean(test1), mean(test2), mean(test3))
}
detach(package:energy)
# plot the empirical estimates of power
plot(sim[,1], sim[,2], ylim = c(0, 1), type = "l",
xlab = bquote(epsilon), ylab = "power")
lines(sim[,1], sim[,3], lty = 2, col=2)
lines(sim[,1], sim[,4], lty = 4, col=3)
abline(h = alpha, lty = 3)
legend("topright", 1, c("skewness", "S-W", "energy"),
lty = c(1,2,4), col=1:3, inset = .02)
# plot the empirical estimates of power
plot(sim[,1], sim[,2], ylim = c(0, 1), type = "l",
xlab = bquote(epsilon), ylab = "power")
lines(sim[,1], sim[,3], lty = 2, col=2)
lines(sim[,1], sim[,4], lty = 4, col=3)
abline(h = alpha, lty = 3)
legend("topright", 1, c("skewness", "S-W", "energy"),
lty = c(1,2,4), col=1:3, inset = .02)
### Example 7.1
set.seed(8)
x=rpois(10,2)
x
table(x)
hist(x)
par(mfrow=c(1,2))
plot(ecdf(x))
plot(ecdf(rpois(1000,2)), main='Poi(2)', ylab="F(x)")
library(bootstrap)    #for the law data
law
cor(law$LSAT, law$GPA)
law82
cor(law$LSAT, law$GPA)
cor(law82$LSAT, law82$GPA)
#set up the bootstrap
B <- 200            #number of replicates
n <- nrow(law)      #sample size
R <- numeric(B)     #storage for replicates
#bootstrap estimate of standard error of R
for (b in 1:B) {
#randomly select the indices
i <- sample(1:n, size = n, replace = TRUE)
LSAT <- law$LSAT[i]       #i is a vector of indices
GPA <- law$GPA[i]
R[b] <- cor(LSAT, GPA)
}
R
#output
se.R <- sd(R)
se.R
dev.off()
hist(R, prob = TRUE)
abline(v=cor(law$LSAT, law$GPA))
r <- function(x, i) {
#want correlation of columns 1 and 2
cor(x[i,1], x[i,2])
}
r <- function(x, i) {
#want correlation of columns 1 and 2
cor(x[i,1], x[i,2])
}
library(boot)       #for boot function
?boot    # check statistic
obj <- boot(data = law, statistic = r, R = 2000)
obj
obj <- boot(data = law, statistic = r, R = 2000)
obj
#sample estimate for n=15
theta.hat <- cor(law$LSAT, law$GPA)
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
LSAT <- law$LSAT[i]
GPA <- law$GPA[i]
theta.b[b] <- cor(LSAT, GPA)
}
bias <- mean(theta.b - theta.hat)
bias
theta.hat
# compare
obj
#sample estimate for n=15
theta.hat <- cor(law$LSAT, law$GPA)
#bootstrap estimate of bias
B <- 2000   #larger for estimating bias
n <- nrow(law)
theta.b <- numeric(B)
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
LSAT <- law$LSAT[i]
GPA <- law$GPA[i]
theta.b[b] <- cor(LSAT, GPA)
}
bias <- mean(theta.b - theta.hat)
bias
# compare
obj
data(patch, package = "bootstrap")
patch
n <- nrow(patch)  #in bootstrap package
B <- 2000
theta.b <- numeric(B)
theta.hat <- mean(patch$y) / mean(patch$z)
#bootstrap
for (b in 1:B) {
i <- sample(1:n, size = n, replace = TRUE)
y <- patch$y[i]
z <- patch$z[i]
theta.b[b] <- mean(y) / mean(z)
}
bias <- mean(theta.b) - theta.hat
se <- sd(theta.b)
print(list(est=theta.hat, bias = bias,
se = se))
