rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R", ylim=c(.99,max(rhat[(b+1):n])))
abline(h=1.1, lty=2)
#plot the sequence of R-hat statistics
set.seed(123)
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j]);abline(h=0)
plot(rhat[(b+1):n], type="l", xlab="", ylab="R", ylim=c(.99,max(rhat[(b+1):n])))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi));abline(h=0)
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k){
plot(psi[i, (b+1):n], type="l", xlab=i, ylab=bquote(psi))
abline(h=0)
}
sigma <- 10     #parameter of proposal distribution
k <- 4          #number of chains to generate
n <- 15000      #length of chains
b <- 1000       #burn-in length
#choose overdispersed initial values
x0 <- c(-10, -5, 5, 10)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k)
X[i, ] <- normal.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k){
plot(psi[i, (b+1):n], type="l", xlab=i, ylab=bquote(psi))
abline(h=0)
}
sigma <- 2     #parameter of proposal distribution
k <- 4          #number of chains to generate
n <- 15000      #length of chains
b <- 1000       #burn-in length
#choose overdispersed initial values
x0 <- c(-10, -5, 5, 10)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k)
X[i, ] <- normal.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi))
par(mfrow=c(1,1)) #restore default
#plot the sequence of R-hat statistics
set.seed(123)
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R")
abline(h=1.1, lty=2)
sigma <- .2     #parameter of proposal distribution
k <- 4          #number of chains to generate
n <- 15000      #length of chains
b <- 1000       #burn-in length
#choose overdispersed initial values
x0 <- c(-10, -5, 5, 10)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k)
X[i, ] <- normal.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi))
par(mfrow=c(1,1)) #restore default
#plot the sequence of R-hat statistics
set.seed(123)
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R")
abline(h=1.1, lty=2)
plot(rhat[(b+1):n], type="l", xlab="", ylab="R", ylim=c(1,max(rhat[(b+1):n])))
abline(h=1.1, lty=2)
dev.off()
normal.chain <- function(sigma, N, X1) {
#generates a Metropolis chain for Normal(0,1)
#with Normal(X[t], sigma) proposal distribution
#and starting value X1
x <- rep(0, N)
x[1] <- X1
u <- runif(N)
for (i in 2:N) {
xt <- x[i-1]
y <- rnorm(1, xt, sigma)     #candidate point
r1 <- dnorm(y, 0, 1) * dnorm(xt, y, sigma)
r2 <- dnorm(xt, 0, 1) * dnorm(y, xt, sigma)
r <- r1 / r2
if (u[i] <= r) x[i] <- y else
x[i] <- xt
}
return(x)
}
sigma <- 2     #parameter of proposal distribution
k <- 4          #number of chains to generate
n <- 15000      #length of chains
b <- 1000       #burn-in length
#choose overdispersed initial values
x0 <- c(-10, -5, 5, 10)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k)
X[i, ] <- normal.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi))
par(mfrow=c(1,1)) #restore default
#plot the sequence of R-hat statistics
set.seed(123)
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R", ylim=c(1,max(rhat[(b+1):n])))
abline(h=1.1, lty=2)
sigma <- .2     #parameter of proposal distribution
k <- 4          #number of chains to generate
n <- 15000      #length of chains
b <- 1000       #burn-in length
#choose overdispersed initial values
x0 <- c(-10, -5, 5, 10)
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k)
X[i, ] <- normal.chain(sigma, n, x0[i])
#compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi))
psi[i,] <- psi[i,] / (1:ncol(psi))
print(Gelman.Rubin(psi))
#plot psi for the four chains
set.seed(123)
par(mfrow=c(2,2))
for (i in 1:k)
plot(psi[i, (b+1):n], type="l",
xlab=i, ylab=bquote(psi))
par(mfrow=c(1,1)) #restore default
#plot the sequence of R-hat statistics
set.seed(123)
rhat <- rep(0, n)
for (j in (b+1):n)
rhat[j] <- Gelman.Rubin(psi[,1:j])
plot(rhat[(b+1):n], type="l", xlab="", ylab="R", ylim=c(1,max(rhat[(b+1):n])))
abline(h=1.1, lty=2)
?rnorm
### Example 14.5 (EM algorithm for a mixture model)
set.seed(543)
theta=10
a=11
n=100
m=70
x=rnorm(m, theta, 1)
mu0=0
iter=1000
mu=0
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, 'l')
plot(mu, type='l')
mu
j=1
m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
m*mean(x)/n
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
mu[j]
dnorm(a-mu[j])
1-pnorm(a-mu[j])
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
mu
plot(mu)
mu=2
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
mu
mu=3
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
mu
### Example 14.5 (EM algorithm for a mixture model)
set.seed(543)
theta=10
a=11
n=100
m=50
x=rnorm(m, theta, 1)
iter=1000
mu=3
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(543)
theta=10
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=1000
mu=3
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(543)
theta=10
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=3
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(543)
theta=10
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=15
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu)
mu
### Example 14.5 (EM algorithm for a mixture model)
set.seed(543)
theta=10
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu)
plot(mu, type='l')
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=11
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l')
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=5
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l')
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=50
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l')
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=30
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l')
abline(h=theta, col=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=30
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=10
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=90
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=99
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=100
m=1
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=1000
m=1
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=1000
m=10
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=1000
m=900
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
### Example 14.5 (EM algorithm for a mixture model)
set.seed(123)
theta=10
a=10.5
n=1000
m=500
x=rnorm(m, theta, 1)
iter=20
mu=5
for (j in 1:iter) {
mu[j+1] = m*mean(x)/n +
(n-m)*(mu[j]+dnorm(a-mu[j])/(1-pnorm(a-mu[j])))/n
}
plot(mu, type='l', lwd=2)
abline(h=theta, col=2, lwd=2)
